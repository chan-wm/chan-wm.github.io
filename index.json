[{"authors":["admin"],"categories":null,"content":"I am a software engineer at BenevolentAI, working on technology that uses machine learning and AI for drug discovery. I am passionate about technology, biology and the intersection between the two.\nI hold an integrated master\u0026rsquo;s degree in biomedical engineering from Imperial College London, specialising in computational bioengineering. My studies focused on using computational techniques such as machine learning, data science, computer vision and signal processing to solve biomedical and healthcare problems.\n","date":-62135596800,"expirydate":-62135596800,"kind":"term","lang":"en","lastmod":-62135596800,"objectID":"2525497d367e79493fd32b198b28f040","permalink":"https://chan.github.io/authors/admin/","publishdate":"0001-01-01T00:00:00Z","relpermalink":"/authors/admin/","section":"authors","summary":"I am a software engineer at BenevolentAI, working on technology that uses machine learning and AI for drug discovery. I am passionate about technology, biology and the intersection between the two.\nI hold an integrated master\u0026rsquo;s degree in biomedical engineering from Imperial College London, specialising in computational bioengineering. My studies focused on using computational techniques such as machine learning, data science, computer vision and signal processing to solve biomedical and healthcare problems.","tags":null,"title":"Chanasak Mahankarat","type":"authors"},{"authors":null,"categories":null,"content":"This project was completed, awarded First Class Honours and submitted as part of the requirements for my master of engineering degree at Imperial College London. I worked as part of the Biological Control Systems Lab and was supervised by Dr. Reiko Tanaka and Dr. Rahman Attar.\nAspergillus fumigatus and invasive aspergillosis Aspergillus fumigatus (A. fumigatus) is a ubiquitous fungus that humans are exposed to everyday. A. fumigatus reproduces asexually by releasing conidia, a type of asexual spores that germinates into hyphae, into the atmosphere. These airborne conidia have a sufficiently small diameter of 2-3 μm to reach the lung alveoli and humans inhale several hundred conidia per day.\nInhalation of conidia can cause various illnesses depending on the immune status of the host. In immunocompetent individuals, there is rarely any adverse effect since the conidia are efficiently neutralised and eliminated by the immune system. However, in immunocompromised patients, it can cause life-threatening invasive aspergillosis (IA) where the conidia germinates into hyphae that invade the lungs and can spread rapidly to other parts of the body such as brain, heart and kidneys which can result in death.\nFigure 1: Inhalation of conidia resulting in the germination of hyphae in immunocompromised patients\rQuantification of fungal burden Quantifying fungal burden is important for tracking the disease progression and evaluating the effectiveness of the novel therapeutics. However, enumeration of fungal burden and extent of tissue invasion in histology images is still done manually, which is a tedious and time-consuming task and prone to error.\nTo quantify the fungal burden, we first calculate the tissue area by converting the histology image into a binary image through a thresholding technique and counting the number of black pixels which correspond to the tissue pixels. Next, the fungal area is calculated by using a convolutional neural network to segment the fungi region from the histology image and counting the number of white pixels in it as they correspond to the fungi pixels. Finally, the fungal buden is calculated by dividing the fungal area by the tissue area.\nFigure 2: Quantification of fungal burden\rDataset Dataset consisted of 149 512-by-1024 pixels GMS stained patch-level histology images of murine lung infected with A. fumigatus and their corresponding pathologist-verified ground truth binary segmented masks\nFigure 5: The process of collecting the dataset Semantic image segnmentation and convolutional neural network Semantic image segmentation classifies every pixel of an image with a class label. In our application, this means labelling each pixel in the histology images as fungi or non-fungi. Convolutional neural network (CNN) is a deep learning architecture inspired by the natural visual perception mechanism. CNN learns important features in images in order to perform prediction, classification and segmentation tasks. CNN has been widely used in multiple biomedical image analysis tasks. In histology images, CNN has been used to segment out certain tissue types such as leukocytes, lymphocytes and erythocytes, showing great promise in quantifying the fungal burden.\nCNN architectures for semantic segmentation usually incorporate encoder and decoder networks. The encoder network reduces the size of an image to capture important details of the image. This allows the model to learn important features of the image, however, it loses the spatial information. The decoder network restores back the resolution of the image, allowing the learned features to be localised and used to construct the segmented image.\nIn this project, we explored 4 popular segmentation network architectures FCN, U-Net, SegNet and PSPNet, and 2 different pre-trained model backbones VGG16 and ResNet50. We found that VGG U-Net model gave the highest mean DICE score when evaluated using 5-fold cross-validation.\nFigure 3: Architecture of U-Net (Ronneberger et al., 2015)\rFigure 4: Architecture of VGG-16 (Simonyan \u0026 Zisserman, 2015)\rData augmentation Deep learning techniques relies heavily on large datasets to allow the model to generalise and avoid overfitting as the model is exposed to more training examples. However, for biomedical images such as histology images, collecting and labelling data can be a very laborious task. Data augmentation is a technique of artificially expanding the size and variety of the dataset by applying image transformations on the existing dataset. For this project, we used both geometric and colour transformation. For each input original image, 10 augmented images were generated, inflating the training set by 10 times.\nResults The VGG U-Net achieved the mean DICE score of 0.74±0.03. Figure 6 shows sample plots of the segmentation predicted as well as the predicted fungal burden quantification.\nFigure 6: Sample plot of the segmentation and the fungal burden quantification\rFull report The full report is available in the PDF format below\n","date":1657411200,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1657411200,"objectID":"c83e582e1201da8e07cb8bb1ecea0e8d","permalink":"https://chan.github.io/project/quantification-of-fungal-burden-in-histology-images/","publishdate":"2022-07-10T00:00:00Z","relpermalink":"/project/quantification-of-fungal-burden-in-histology-images/","section":"project","summary":"Using deep learning to quantify fungal burden in histology images","tags":["AI in Healthcare","Deep Learning","Computer Vision","Image Segmentation"],"title":"Quantification of fungal burden in histology images","type":"project"},{"authors":[],"categories":[],"content":"Welcome to Slides academia\nFeatures Efficiently write slides in Markdown 3-in-1: Create, Present, and Publish your slides Supports speaker notes Mobile friendly slides Controls Next: Right Arrow or Space Previous: Left Arrow Start: Home Finish: End Overview: Esc Speaker notes: S Fullscreen: F Zoom: Alt + Click PDF Export: E Code Highlighting Inline code: variable\nCode block:\nporridge = \u0026#34;blueberry\u0026#34; if porridge == \u0026#34;blueberry\u0026#34;: print(\u0026#34;Eating...\u0026#34;) Math In-line math: $x + y = z$\nBlock math:\n$$ f\\left( x \\right) = ;\\frac{{2\\left( {x + 4} \\right)\\left( {x - 4} \\right)}}{{\\left( {x + 4} \\right)\\left( {x + 1} \\right)}} $$\nFragments Make content appear incrementally\n{{% fragment %}} One {{% /fragment %}}\r{{% fragment %}} **Two** {{% /fragment %}}\r{{% fragment %}} Three {{% /fragment %}} Press Space to play!\nA fragment can accept two optional parameters:\nclass: use a custom style (requires definition in custom CSS) weight: sets the order in which a fragment appears Speaker Notes Add speaker notes to your presentation\n{{% speaker_note %}} - Only the speaker can read these notes - Press `S` key to view {{% /speaker_note %}} Press the S key to view the speaker notes!\nOnly the speaker can read these notes Press S key to view Themes black: Black background, white text, blue links (default) white: White background, black text, blue links league: Gray background, white text, blue links beige: Beige background, dark text, brown links sky: Blue background, thin dark text, blue links night: Black background, thick white text, orange links serif: Cappuccino background, gray text, brown links simple: White background, black text, blue links solarized: Cream-colored background, dark green text, blue links Custom Slide Customize the slide style and background\n{{\u0026lt; slide background-image=\u0026#34;/img/boards.jpg\u0026#34; \u0026gt;}} {{\u0026lt; slide background-color=\u0026#34;#0000FF\u0026#34; \u0026gt;}} {{\u0026lt; slide class=\u0026#34;my-style\u0026#34; \u0026gt;}} Custom CSS Example Let\u0026rsquo;s make headers navy colored.\nCreate assets/css/reveal_custom.css with:\n.reveal section h1, .reveal section h2, .reveal section h3 { color: navy; } Questions? Ask\nDocumentation\n","date":1549324800,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1549324800,"objectID":"0e6de1a61aa83269ff13324f3167c1a9","permalink":"https://chan.github.io/slides/example/","publishdate":"2019-02-05T00:00:00Z","relpermalink":"/slides/example/","section":"slides","summary":"An introduction to using academia's Slides feature.","tags":[],"title":"Slides","type":"slides"}]